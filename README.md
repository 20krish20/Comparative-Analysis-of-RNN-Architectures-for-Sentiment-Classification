# ğŸ“˜ Homework 3 â€” NLP: Comparative Analysis of RNN Architectures  
**Krishnendra Singh Tomar â€“ Data Science (M.S.) â€“ University of Maryland, College Park**

---

# ğŸ“Œ 1. Project Overview

This project performs a **comparative experimental study** of Recurrent Neural Network (RNN) architectures for **binary sentiment classification** on the IMDb movie review dataset (50,000 reviews).

We systematically vary the following components:

### âœ” Architecture  
- RNN  
- LSTM  
- Bidirectional LSTM  

### âœ” Activation Function  
- ReLU  
- Tanh  
- Sigmoid  

### âœ” Optimizer  
- Adam  
- SGD  
- RMSProp  

### âœ” Sequence Length  
- 25  
- 50  
- 100  

### âœ” Gradient Stability  
- With vs. without **gradient clipping**

The objective is to build a **fully reproducible endâ€‘toâ€‘end NLP pipeline** while evaluating how architectural, training, and preprocessing choices affect performance under **CPUâ€‘only constraints.**

---

# ğŸ“‚ 2. Repository Structure

```
homework3-NLP/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ IMDB Dataset.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ imdb_len25.npz
â”‚       â”œâ”€â”€ imdb_len50.npz
â”‚       â”œâ”€â”€ imdb_len100.npz
â”‚       â”œâ”€â”€ tokenizer_top10k.json
â”‚       â”œâ”€â”€ vocab_top10k.txt
â”‚       â””â”€â”€ imdb_prep_summary.csv
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ metrics.csv
â”‚   â”œâ”€â”€ model_*.pt
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ accuracy_by_arch.png
â”‚       â”œâ”€â”€ accuracy_by_activation.png
â”‚       â”œâ”€â”€ accuracy_by_optimizer.png
â”‚       â”œâ”€â”€ accuracy_by_seq_len.png
â”‚       â””â”€â”€ accuracy_by_clip_grad.png
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ plot_results.py
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ report.pdf
```

---

# ğŸ“Š 3. Dataset Description

**Source:**  
IMDb Movie Review Dataset (50,000 labeled reviews)  
<https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews>

**Properties:**  
- 50,000 reviews  
- Balanced: 25k positive / 25k negative  
- Uses predefined **25k train / 25k test** split  

### Preprocessing Steps (in `preprocess.py`)
1. Convert to lowercase  
2. Remove punctuation & special characters  
3. Tokenize  
4. Keep **top 10,000 most frequent words**  
5. Convert tokens â†’ integer IDs  
6. Pad/truncate to fixed lengths: **25, 50, 100** tokens  
7. Save sequences as `.npz` files  

Outputs include:  
- `tokenizer_top10k.json`  
- `vocab_top10k.txt`  
- `imdb_prep_summary.csv`  
- Sequence datasets for each length  

---

# âš™ï¸ 4. Environment Setup

### Python Version
**Python 3.10+ recommended**

### Install Dependencies
```
pip install -r requirements.txt
```

### (Optional) Create Virtual Environment
```
python3 -m venv .venv
source .venv/bin/activate   # macOS/Linux
# .venv\Scriptsctivate    # Windows
pip install -r requirements.txt
```

---

# ğŸ§¼ 5. Preprocessing the Dataset

Place the IMDb CSV in:

```
data/raw/IMDB Dataset.csv
```

Then run:

```
python -m src.preprocess   --raw_csv "data/raw/IMDB Dataset.csv"   --output_dir data/processed   --top_k 10000   --seq_lengths 25 50 100   --seed 42
```

This generates all processed `.npz` files and tokenizer artifacts.

---

# ğŸ§  6. Model Architecture

`TextRNNClassifier` (in `models.py`) supports:

- **RNN**
- **LSTM**
- **BiLSTM**

### Shared Hyperparameters
| Component | Value |
|----------|--------|
| Embedding dim | 100 |
| Hidden size | 64 |
| Layers | 2 |
| Dropout | 0.5 |
| Output | Sigmoid |
| Loss | Binary Crossâ€‘Entropy |
| Batch size | 32 |

---

# ğŸš€ 7. Training Models

### General Command
```
python -m src.train   --arch <rnn|lstm|bilstm>   --activation <relu|tanh|sigmoid>   --optimizer <adam|sgd|rmsprop>   --seq_len <25|50|100>   [--clip_grad]   [--epochs N]
```

### Example (LSTM Baseline)
```
python -m src.train --arch lstm --activation relu --optimizer adam --seq_len 50
```

### What training produces:
- A model checkpoint (`model_*.pt`)
- A metrics row appended to `results/metrics.csv`:
  - arch  
  - activation  
  - optimizer  
  - seq_len  
  - clip_grad  
  - accuracy  
  - train_time  
  - checkpoint  

---

# ğŸ§ª 8. Evaluation

Evaluate any saved model:

```
python -m src.evaluate   --arch lstm   --activation relu   --seq_len 100   --checkpoint results/model_lstm_relu_adam_len100_clip0.pt
```

Outputs include:  
- Accuracy  
- Precision  
- Recall  
- F1â€‘score  
- Confusion matrix  

---

# ğŸ“ˆ 9. Generating Plots

```
python -m src.plot_results
```

This reads `metrics.csv` and creates:

- `accuracy_by_arch.png`
- `accuracy_by_activation.png`
- `accuracy_by_optimizer.png`
- `accuracy_by_seq_len.png`
- `accuracy_by_clip_grad.png`

These plots go directly into **report.pdf**.

---

# ğŸ§¾ 10. Recommended Experiment Set

## Architecture Comparison
```
python -m src.train --arch rnn   --activation relu --optimizer adam --seq_len 50
python -m src.train --arch lstm  --activation relu --optimizer adam --seq_len 50
python -m src.train --arch bilstm --activation relu --optimizer adam --seq_len 50
```

## Activation Comparison
```
python -m src.train --arch lstm --activation relu    --optimizer adam --seq_len 50
python -m src.train --arch lstm --activation tanh    --optimizer adam --seq_len 50
python -m src.train --arch lstm --activation sigmoid --optimizer adam --seq_len 50
```

## Optimizer Comparison
```
python -m src.train --arch lstm --activation relu --optimizer adam    --seq_len 50
python -m src.train --arch lstm --activation relu --optimizer rmsprop --seq_len 50
python -m src.train --arch lstm --activation relu --optimizer sgd     --seq_len 50
```

## Sequence Length Comparison
```
python -m src.train --arch lstm --activation relu --optimizer adam --seq_len 25
python -m src.train --arch lstm --activation relu --optimizer adam --seq_len 50
python -m src.train --arch lstm --activation relu --optimizer adam --seq_len 100
```

## Gradient Clipping Comparison
```
python -m src.train --arch lstm --activation relu --optimizer adam --seq_len 50
python -m src.train --arch lstm --activation relu --optimizer adam --seq_len 50 --clip_grad
```

---

# ğŸ” 11. Reproducibility

This project ensures full reproducibility via:

- Seeded randomness (`torch`, `numpy`, `random`)  
- Tokenizer saved to disk  
- Full experiment logs in `metrics.csv`  
- Code modularized under `src/`  
- Plots autoâ€‘generated from experiment results  

A new user can reproduce everything by:

1. Installing dependencies  
2. Running preprocessing  
3. Running the experiments above  
4. Generating plots  
5. Evaluating final models  

---

# ğŸ›  12. Troubleshooting

### FileNotFoundError: imdb_len*.npz  
â†’ Run preprocessing first.

### ModuleNotFoundError: torch / matplotlib  
â†’ Ensure you ran:
```
pip install -r requirements.txt
```

### Plots not updating  
â†’ Delete `metrics.csv` and reâ€‘run experiments.

---

# ğŸ 13. Final Notes

This README is designed to satisfy the **full rubric requirements**:

- âœ” Code implementation  
- âœ” Experimental design  
- âœ” Results + plots  
- âœ” Reproducibility  
- âœ” Documentation clarity  

Your repository and report should now be fully ready for submission.

Good luck â€” and great work keeping everything clean and reproducible! ğŸ‰
